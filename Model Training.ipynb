{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef852a84",
   "metadata": {},
   "source": [
    "# Bismillah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "891df4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f996af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e33239",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pickle.load(open('pipeline.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4391f7dd",
   "metadata": {},
   "source": [
    "## 4. Split the Data\n",
    "\n",
    "- Divide your data into training and testing sets (commonly a 70-30 or 80-20 split). This helps in evaluating the model on unseen data to gauge its generalization capability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b9d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ndf=df\n",
    "X=df.drop(columns=['income'])\n",
    "y=df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d79c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b35ae80",
   "metadata": {},
   "source": [
    "#### Transform the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af7258be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "X_test_transformed = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b17a27",
   "metadata": {},
   "source": [
    "## 5. Choose a Model\n",
    "-     Classification: Logistic Regression, Decision Trees, SVM, Random Forest, Gradient Boosting Machines, Neural Networks.\n",
    "-    Regression: Linear Regression, Ridge, Lasso, SVR, Random Forest Regressor, Gradient Boosting Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7e0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "798200ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionCV(cv=5, random_state=42, Cs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9903bd0",
   "metadata": {},
   "source": [
    "## 6. Train the Model\n",
    "\n",
    "- Train your model using the training data. This involves fitting the model to the data and adjusting parameters. Use cross-validation to ensure that the model generalizes well over different subsets of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8d6884c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(cv=5, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_transformed, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "581e8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testing data\n",
    "\n",
    "y_pred = model.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7696fdf2",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "\n",
    "- Evaluate the model using appropriate metrics:\n",
    "\n",
    "   - Classification: Accuracy, Precision, Recall, F1-Score, ROC-AUC.\n",
    "   - Regression: MSE, RMSE, MAE, RÂ²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c3e9a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd76d31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.54%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7176ed81",
   "metadata": {},
   "source": [
    "## 8. Model Refinement\n",
    "\n",
    "- Refine the model based on evaluation metrics. This may involve returning to feature engineering, trying different models, or tuning hyperparameters further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de687435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72c62aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ccebdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "                \"Random Forest\": RandomForestClassifier(),\n",
    "                \"Decision Tree\": DecisionTreeClassifier(),\n",
    "                \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "                \"AdaBoost\": AdaBoostClassifier(),\n",
    "            } \n",
    "\n",
    "params={\n",
    "                \"Decision Tree\": {\n",
    "                    'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "                    # 'splitter':['best','random'],\n",
    "                    # 'max_features':['sqrt','log2'],\n",
    "                },\n",
    "                \"Random Forest\":{\n",
    "                    # 'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "                 \n",
    "                    # 'max_features':['sqrt','log2',None],\n",
    "                    'n_estimators': [8,16,32,64,128,256]\n",
    "                },\n",
    "                \"Gradient Boosting\":{\n",
    "                    # 'loss':['squared_error', 'huber', 'absolute_error', 'quantile'],\n",
    "                    'learning_rate':[.1,.01,.05,.001],\n",
    "                    'subsample':[0.6,0.7,0.75,0.8,0.85,0.9],\n",
    "                    # 'criterion':['squared_error', 'friedman_mse'],\n",
    "                    # 'max_features':['auto','sqrt','log2'],\n",
    "                    'n_estimators': [8,16,32,64,128,256]\n",
    "                },\n",
    "                \n",
    "                \"AdaBoost\":{\n",
    "                    'learning_rate':[.1,.01,0.5,.001],\n",
    "                    # 'loss':['linear','square','exponential'],\n",
    "                    'n_estimators': [8,16,32,64,128,256]\n",
    "                }\n",
    "                \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eedaff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X_train, y_train,X_test,y_test,models,param):\n",
    "    try:\n",
    "        report = {}\n",
    "\n",
    "        for i in range(len(list(models))):\n",
    "            \n",
    "            model = list(models.values())[i]\n",
    "            para=param[list(models.keys())[i]]\n",
    "\n",
    "            model.fit(X_train_transformed,y_train)\n",
    "\n",
    "            #model.fit(X_train, y_train)  # Train model\n",
    "\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test_transformed)\n",
    "            \n",
    "            train_model_score = accuracy_score(y_train, y_train_pred)\n",
    "            test_model_score = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "            report[list(models.keys())[i]] = test_model_score          \n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a642ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_report:dict=evaluate_models(X_train=X_train_transformed,y_train=y_train,X_test=X_test_transformed,y_test=y_test,models=models,param=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93034c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': 0.8265189770320899,\n",
       " 'Decision Tree': 0.7752076885486235,\n",
       " 'Gradient Boosting': 0.8442743117771624,\n",
       " 'AdaBoost': 0.8392246294184721}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab1306dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8442743117771624\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = sorted(model_report.values())[-1]\n",
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ecfbdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keys_by_value(dictionary, target_value):\n",
    "    return [key for key, value in dictionary.items() if value == target_value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f7b9fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gradient Boosting'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = find_keys_by_value(model_report, best_accuracy)\n",
    "best_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c35ca32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_object = models[best_model[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0b0401",
   "metadata": {},
   "source": [
    "##### Make a pickle file of 'Best Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "531fed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model_object,open('best_model_object.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82597ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83626688",
   "metadata": {},
   "source": [
    "## 9. Model Deployment\n",
    "\n",
    "- Once satisfied with the model's performance, deploy it to a production environment. This could be through a REST API, a web application, or by integrating it into existing software systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ce213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15dafc33",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Making Predictions\n",
    "\n",
    "- Use the deployed model to make predictions on new data. Ensure that the new data is preprocessed and transformed in the same way as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2fae6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = best_model_object.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "acfda646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8442743117771624"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6509c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 11. Monitor and Update\n",
    "\n",
    "- Regularly monitor the model's performance as it might degrade over time (concept drift). Update the model periodically by retraining it with new data or tweaking it to maintain accuracy.\n",
    "\n",
    "## 12. Documentation and Reporting\n",
    "\n",
    "- Throughout the process, document your findings, methodology, model parameters, and performance metrics. This is crucial for reproducibility and for stakeholders to understand the model's capabilities and limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
